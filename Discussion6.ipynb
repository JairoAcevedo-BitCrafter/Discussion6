{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "!pip install emot\n",
        "!pip install num2words\n",
        "!pip install afinn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3thX7-qkpil",
        "outputId": "7114b0ef-253a-4c39-bbaa-a21581e99543"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
            "Requirement already satisfied: emot in /usr/local/lib/python3.10/dist-packages (3.1)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (0.5.12)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words) (0.6.2)\n",
            "Requirement already satisfied: afinn in /usr/local/lib/python3.10/dist-packages (0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kVjoFDs_hkJp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#Obtaining the datasets\n",
        "tweets = pd.read_csv('covid19_tweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg, stopwords, wordnet\n",
        "import contractions\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from num2words import num2words\n",
        "from emot.emo_unicode import UNICODE_EMOJI #for EMOJIS\n",
        "from emot.emo_unicode import EMOTICONS_EMO # For EMOTICONS\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y36oFipikrKD",
        "outputId": "1bdbf2e9-9962-4232-cc1e-e14d49d5df9e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lower_case(text):\n",
        "  return text.lower()\n",
        "def rem_lines(text):\n",
        "    return text.strip().replace('\\n', ' ')\n",
        "def rem_tags(text):\n",
        "  return BeautifulSoup(text, \"html.parser\").get_text()\n",
        "def fix_ct(text):\n",
        "    return contractions.fix(text)\n",
        "def rem_stopwords(text):\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  return [word for word in word_tokenize(text) if not word in stop_words]\n",
        "def rem_punct(text):\n",
        "    no_punct = [w.translate(str.maketrans('', '', string.punctuation)) for w in word_tokenize(text)]\n",
        "    return [word for word in no_punct if word.isalpha()]\n",
        "def lemmatize_words(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
        "    pos_tagged_text = nltk.pos_tag(text.split())\n",
        "    return ' '.join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
        "def to_number(text):\n",
        "    return(re.sub(r\"(\\d+)\", lambda x: num2words(int(x.group(0))), text))\n",
        "def convert_emoticons(text):\n",
        "    for emot in EMOTICONS_EMO:\n",
        "        text = text.replace(emot, EMOTICONS_EMO[emot]+\" \".replace(\"\",\"\"))\n",
        "    return text\n",
        "def convert_emojis(text):\n",
        "    for emot in UNICODE_EMOJI:\n",
        "        text = text.replace(emot,UNICODE_EMOJI[emot]+\" \".replace(\"\",\"\"))\n",
        "    return text\n",
        "def clean_text(text):\n",
        "  text = text.lower() # convert to lowercase\n",
        "  text=re.sub(r'[@#]', '', text) #remove tags\n",
        "  return text"
      ],
      "metadata": {
        "id": "jaDB1eFHkwTq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning tweets\n",
        "tweets['text']=tweets['text'].astype(str).apply(lower_case)\n",
        "tweets['text']=tweets['text'].astype(str).apply(rem_lines)\n",
        "tweets['text']=tweets['text'].astype(str).apply(rem_tags)\n",
        "tweets['text']=tweets['text'].astype(str).apply(convert_emoticons)\n",
        "#tweets['text']=tweets['text'].astype(str).apply(convert_emojis)\n",
        "tweets['text']=tweets['text'].astype(str).apply(fix_ct)\n",
        "tweets['text']=tweets['text'].astype(str).apply(rem_stopwords)\n",
        "tweets['text']=tweets['text'].astype(str).apply(rem_punct)\n",
        "tweets['text']=tweets['text'].astype(str).apply(to_number)\n",
        "tweets['text']=tweets['text'].astype(str).apply(lemmatize_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrJG_K-1k2Qw",
        "outputId": "cc672f95-e739-4874-b5e2-0b564e5154f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-b21a517f00ba>:6: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  return BeautifulSoup(text, \"html.parser\").get_text()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentiment analysis using afinn\n",
        "from afinn import Afinn\n",
        "afn = Afinn()\n",
        "scores = [afn.score(article) for article in tweets['text']]\n",
        "sentiment = ['positive' if score > 0\n",
        "                          else 'negative' if score < 0\n",
        "                              else 'neutral'\n",
        "                                  for score in scores]\n",
        "tweets['sentiment']=sentiment\n",
        "tweets['score']=scores\n",
        "print(tweets.loc[:,['text','sentiment','score']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fnBQxYelFEa",
        "outputId": "a12e7b23-f21e-4ce2-ebf0-f23353b58dc9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     text sentiment  score\n",
            "0       ['smelled', 'scent', 'hand', 'sanitizers', 'to...  negative   -7.0\n",
            "1       ['hey', 'yankees', 'yankeespr', 'mlb', 'would'...  negative   -6.0\n",
            "2       ['wdunlap', 'realdonaldtrump', 'trump', 'never...  negative   -9.0\n",
            "3       ['brookbanktv', 'one', 'gift', 'give', 'apprec...  negative   -3.0\n",
            "4       ['july', 'media', 'bulletin', 'novel', 'corona...  negative   -5.0\n",
            "...                                                   ...       ...    ...\n",
            "179103  ['thanks', 'iamohmai', 'nominating', 'wearamas...  negative   -6.0\n",
            "179104  ['year', 'insanity', 'lol', 'httpsSkeptical', ...  negative   -6.0\n",
            "179105  ['ctvnews', 'powerful', 'painting', 'juan', 'l...  negative   -6.0\n",
            "179106  ['students', 'test', 'positive', 'major', 'uni...  negative   -5.0\n",
            "179107  ['stop', 'see', 'stop', 'sabcnews', 'dailysuns...  negative   -9.0\n",
            "\n",
            "[179108 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_ascending = tweets.sort_values(by='score', ascending=True)\n",
        "tweets_descending = tweets.sort_values(by='score', ascending=False)\n",
        "print(tweets_ascending.loc[:,['text','sentiment','score']])\n",
        "print(tweets_descending.loc[:,['text','sentiment','score']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw6kcyLrrQXz",
        "outputId": "1f149b1e-59d1-4619-91d3-5292346f24ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     text sentiment  score\n",
            "139784  ['imhere', 'httpsSkeptical', 'annoyed', 'undec...  negative  -35.0\n",
            "65260   ['feel', 'like', 'keeping', 'death', 'watch', ...  negative  -32.0\n",
            "22760   ['okay', 'snapchat', 'piece', 'fucking', 'shit...  negative  -29.0\n",
            "47711   ['mywestin', 'oregongovbrown', 'httpsSkeptical...  negative  -28.0\n",
            "124441  ['facebook', 'httpsSkeptical', 'annoyed', 'und...  negative  -28.0\n",
            "...                                                   ...       ...    ...\n",
            "83331   ['breesanna', 'great', 'interview', 'anna', 'p...  positive   12.0\n",
            "39175   ['good', 'meets', 'good', 'common', 'good', 's...  positive   12.0\n",
            "131985  ['generalstrike', 'would', 'end', 'covid', 'ca...  positive   12.0\n",
            "49769   ['wow', 'wow', 'wow', 'look', 'terrific', 'eng...  positive   13.0\n",
            "53745   ['welcome', 'mat', 'helps', 'comics', 'cartoon...  positive   15.0\n",
            "\n",
            "[179108 rows x 3 columns]\n",
            "                                                     text sentiment  score\n",
            "53745   ['welcome', 'mat', 'helps', 'comics', 'cartoon...  positive   15.0\n",
            "49769   ['wow', 'wow', 'wow', 'look', 'terrific', 'eng...  positive   13.0\n",
            "39175   ['good', 'meets', 'good', 'common', 'good', 's...  positive   12.0\n",
            "83331   ['breesanna', 'great', 'interview', 'anna', 'p...  positive   12.0\n",
            "131985  ['generalstrike', 'would', 'end', 'covid', 'ca...  positive   12.0\n",
            "...                                                   ...       ...    ...\n",
            "101784  ['justicia', 'annoyed', 'undecided', 'uneasy',...  negative  -28.0\n",
            "39490   ['fuck', 'california', 'usa', 'fuck', 'corona'...  negative  -28.0\n",
            "22760   ['okay', 'snapchat', 'piece', 'fucking', 'shit...  negative  -29.0\n",
            "65260   ['feel', 'like', 'keeping', 'death', 'watch', ...  negative  -32.0\n",
            "139784  ['imhere', 'httpsSkeptical', 'annoyed', 'undec...  negative  -35.0\n",
            "\n",
            "[179108 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spanish sentiment analysis"
      ],
      "metadata": {
        "id": "Oa7PbaRzs3zS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentiment-analysis-spanish\n",
        "!pip install keras tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7bkYyy_xkoh",
        "outputId": "ceab7aa6-6659-428a-9b04-23730b8bfa32"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentiment-analysis-spanish\n",
            "  Downloading sentiment_analysis_spanish-0.0.25-py3-none-any.whl (30.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.0/30.0 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentiment-analysis-spanish\n",
            "Successfully installed sentiment-analysis-spanish-0.0.25\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtaining the datasets\n",
        "spanish = pd.read_csv('EleccionesColombia.csv')\n",
        "print(spanish)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7_WT-5Hs3IR",
        "outputId": "9f221f97-f76d-4532-d7b7-9d882945784b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      tweetID  \\\n",
            "0      ID:1008420713391370240   \n",
            "1      ID:1008420713009762304   \n",
            "2      ID:1008420706957320193   \n",
            "3      ID:1008420706344894464   \n",
            "4      ID:1008420700787433473   \n",
            "...                       ...   \n",
            "29995  ID:1008317884500795392   \n",
            "29996  ID:1008317883900944384   \n",
            "29997  ID:1008317879689928705   \n",
            "29998  ID:1008317872865718273   \n",
            "29999  ID:1008317856801591296   \n",
            "\n",
            "                                               tweetText  \\\n",
            "0      @herbinhoyos @petrogustavo @FiscaliaCol El lad...   \n",
            "1                      @ELTIEMPO @IvanDuque vende patria   \n",
            "2      @_El_Patriota @PoliciaColombia @petrogustavo l...   \n",
            "3      @petrogustavo Es verdad! Yo ya lo hice. https:...   \n",
            "4      La guerra sucia que muestra el desespero de lo...   \n",
            "...                                                  ...   \n",
            "29995  El que es sinvergüenza, deja esperando al que ...   \n",
            "29996  @molemc79 @jarax12 @christian__rev @mejornonon...   \n",
            "29997  @PalomaValenciaL @IvanDuque Parece una loca!!!...   \n",
            "29998  @NomasLaPuntica_ @elespectador @IvanDuque Much...   \n",
            "29999  @AlvaroUribeVel @IvanDuque @mluciaramirez Doct...   \n",
            "\n",
            "                                                    urls  tweetRetweetCt  \\\n",
            "0                                                     []               0   \n",
            "1                                                     []               0   \n",
            "2                                                     []               0   \n",
            "3                                                     []               0   \n",
            "4      [{'url': 'https://t.co/10p4oUtbuW', 'expanded_...               0   \n",
            "...                                                  ...             ...   \n",
            "29995                                                 []               0   \n",
            "29996                                                 []               0   \n",
            "29997                                                 []               0   \n",
            "29998                                                 []               0   \n",
            "29999                                                 []               0   \n",
            "\n",
            "       tweetFavoriteCt          tweetSource         tweetCreated  \\\n",
            "0                    0   Twitter for iPhone  2018-06-17 18:46:48   \n",
            "1                    0   Twitter Web Client  2018-06-17 18:46:48   \n",
            "2                    0   Twitter Web Client  2018-06-17 18:46:46   \n",
            "3                    0  Twitter for Android  2018-06-17 18:46:46   \n",
            "4                    0             Facebook  2018-06-17 18:46:45   \n",
            "...                ...                  ...                  ...   \n",
            "29995                0  Twitter for Android  2018-06-17 11:58:11   \n",
            "29996                0         Twitter Lite  2018-06-17 11:58:11   \n",
            "29997                0  Twitter for Android  2018-06-17 11:58:10   \n",
            "29998                1         Twitter Lite  2018-06-17 11:58:09   \n",
            "29999                0   Twitter for iPhone  2018-06-17 11:58:05   \n",
            "\n",
            "                      userID      userScreen              userName  \\\n",
            "0                ID:20771560       dani10mas                Daniel   \n",
            "1               ID:226964824    sebito641955       gustavo  medina   \n",
            "2               ID:212086212       gloinsedi       GloryaInéSerna.   \n",
            "3              ID:2940867190      Vainilla40             País de M   \n",
            "4               ID:165567718   GallegoSamuel        Samuel Gallego   \n",
            "...                      ...             ...                   ...   \n",
            "29995          ID:2727195329      cmendoza71      Cesar Mendoza 🥑🐝   \n",
            "29996            ID:69367638    3208eliarqui  إليانا أرانغو Eli A.   \n",
            "29997          ID:3615573856  tigrerayado015  tigrerayado@gmail.co   \n",
            "29998           ID:174705127        crispugo       Cristian Puerto   \n",
            "29999  ID:860245384748306433  encuestaidiota      Encuesta Idiotas   \n",
            "\n",
            "              userCreateDt                                           userDesc  \\\n",
            "0      2009-02-13 13:59:04                                                NaN   \n",
            "1      2010-12-15 15:08:50  ciudadano del mundo y del universo .hablo el l...   \n",
            "2      2010-11-05 02:46:52  Administradora Empresas. USACA.  Basta de lame...   \n",
            "3      2014-12-25 15:22:00                                                NaN   \n",
            "4      2010-07-11 23:43:14  Comunicador Social-Periodista de @UMDSoacha. P...   \n",
            "...                    ...                                                ...   \n",
            "29995  2014-07-28 10:39:10  Ni de izquierda ni de derecha, sencillamente d...   \n",
            "29996  2009-08-27 18:38:23  ***Dios, Fisioterapeuta IUEND, me encanta las ...   \n",
            "29997  2015-09-11 01:50:15                                                NaN   \n",
            "29998  2010-08-04 16:24:16                                                NaN   \n",
            "29999  2017-05-04 21:30:57      Hacer preguntas estúpidas a gente inteligente   \n",
            "\n",
            "       userFollowerCt  userFriendsCt          userLocation  userTimezone  \n",
            "0                 135            262                   NaN           NaN  \n",
            "1                 842           1929              colombia           NaN  \n",
            "2                 426           1120              COLOMBIA           NaN  \n",
            "3                  93            367              Colombia           NaN  \n",
            "4                1361           1933      Soacha, Colombia           NaN  \n",
            "...               ...            ...                   ...           ...  \n",
            "29995              97            186                   NaN           NaN  \n",
            "29996             300            495              Colombia           NaN  \n",
            "29997              26             97  Bogotá, DC, Colombia           NaN  \n",
            "29998             319            761                   NaN           NaN  \n",
            "29999              13            140       New Jersey, USA           NaN  \n",
            "\n",
            "[30000 rows x 16 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning tweets\n",
        "spanish['tweetText']=spanish['tweetText'].astype(str).apply(clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4RCsbTiwukB",
        "outputId": "f59d4b5a-7192-406f-fd22-899c1822a5ca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        herbinhoyos petrogustavo fiscaliacol el ladrón...\n",
            "1                          eltiempo ivanduque vende patria\n",
            "2        _el_patriota policiacolombia petrogustavo lei ...\n",
            "3        petrogustavo es verdad! yo ya lo hice. https:/...\n",
            "4        la guerra sucia que muestra el desespero de lo...\n",
            "                               ...                        \n",
            "29995    el que es sinvergüenza, deja esperando al que ...\n",
            "29996    molemc79 jarax12 christian__rev mejornonono cl...\n",
            "29997    palomavalencial ivanduque parece una loca!!! n...\n",
            "29998    nomaslapuntica_ elespectador ivanduque muchos ...\n",
            "29999    alvarouribevel ivanduque mluciaramirez doctor,...\n",
            "Name: tweetText, Length: 30000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentiment analysis\n",
        "from sentiment_analysis_spanish import sentiment_analysis\n",
        "sent_span = sentiment_analysis.SentimentAnalysisSpanish()\n",
        "scores = [sent_span.sentiment(article) for article in spanish['tweetText']]\n",
        "sentiment = ['positive' if score > 0.5\n",
        "                          else 'negative' if score < 0.5\n",
        "                              else 'neutral'\n",
        "                                  for score in scores]\n",
        "spanish['sentiment']=sentiment\n",
        "spanish['score']=scores\n",
        "print(spanish.loc[:,['tweetText','sentiment','score']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMxl60nDzqGT",
        "outputId": "9f56efa5-9ff4-4797-e78f-4c4bc850304c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweetText sentiment  \\\n",
            "0      herbinhoyos petrogustavo fiscaliacol el ladrón...  negative   \n",
            "1                        eltiempo ivanduque vende patria  negative   \n",
            "2      _el_patriota policiacolombia petrogustavo lei ...  negative   \n",
            "3      petrogustavo es verdad! yo ya lo hice. https:/...  negative   \n",
            "4      la guerra sucia que muestra el desespero de lo...  negative   \n",
            "...                                                  ...       ...   \n",
            "29995  el que es sinvergüenza, deja esperando al que ...  negative   \n",
            "29996  molemc79 jarax12 christian__rev mejornonono cl...  negative   \n",
            "29997  palomavalencial ivanduque parece una loca!!! n...  negative   \n",
            "29998  nomaslapuntica_ elespectador ivanduque muchos ...  negative   \n",
            "29999  alvarouribevel ivanduque mluciaramirez doctor,...  negative   \n",
            "\n",
            "              score  \n",
            "0      2.382450e-01  \n",
            "1      4.978923e-01  \n",
            "2      7.821248e-02  \n",
            "3      3.397092e-02  \n",
            "4      9.762036e-08  \n",
            "...             ...  \n",
            "29995  4.077235e-06  \n",
            "29996  1.459726e-04  \n",
            "29997  7.310791e-06  \n",
            "29998  7.389345e-06  \n",
            "29999  5.314209e-03  \n",
            "\n",
            "[30000 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sorting for easier analysis\n",
        "spanish_ascending = spanish.sort_values(by='score', ascending=True)\n",
        "spanish_descending = spanish.sort_values(by='score', ascending=False)\n",
        "print(spanish_ascending.loc[:,['tweetText','sentiment','score']])\n",
        "print(spanish_descending.loc[:,['tweetText','sentiment','score']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZl2BS7v2lwf",
        "outputId": "e71ce953-856c-47d0-c154-f7f0b421355c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweetText sentiment  \\\n",
            "29647  juanescor apoilonia ivanduque yo no soy petris...  negative   \n",
            "28153  cecastaneda petrogustavo a_ordonezm 16oscarsan...  negative   \n",
            "29279  olaznogjunior jessicacediel ivanduque que una ...  negative   \n",
            "11424  petrogustavo hablan de petro diciendo que es d...  negative   \n",
            "8283   jjtellezf petrogustavo resulta que no es porqu...  negative   \n",
            "...                                                  ...       ...   \n",
            "25497  en el hotel ghl de la ciudad de barranquilla e...  positive   \n",
            "28001  saludhernandezm cuando petrogustavo fue alcald...  positive   \n",
            "24286  apoilonia ivanduque el odio y el resentimiento...  positive   \n",
            "25674  elcolombiano petrogustavo nótese la brecha y e...  positive   \n",
            "16959  elecciones ivanduque  esperará los resultados ...  positive   \n",
            "\n",
            "              score  \n",
            "29647  3.031789e-23  \n",
            "28153  1.880022e-21  \n",
            "29279  3.530098e-21  \n",
            "11424  1.334412e-20  \n",
            "8283   1.569570e-20  \n",
            "...             ...  \n",
            "25497  9.999986e-01  \n",
            "28001  9.999998e-01  \n",
            "24286  9.999999e-01  \n",
            "25674  1.000000e+00  \n",
            "16959  1.000000e+00  \n",
            "\n",
            "[30000 rows x 3 columns]\n",
            "                                               tweetText sentiment  \\\n",
            "16959  elecciones ivanduque  esperará los resultados ...  positive   \n",
            "25674  elcolombiano petrogustavo nótese la brecha y e...  positive   \n",
            "24286  apoilonia ivanduque el odio y el resentimiento...  positive   \n",
            "28001  saludhernandezm cuando petrogustavo fue alcald...  positive   \n",
            "25497  en el hotel ghl de la ciudad de barranquilla e...  positive   \n",
            "...                                                  ...       ...   \n",
            "8283   jjtellezf petrogustavo resulta que no es porqu...  negative   \n",
            "11424  petrogustavo hablan de petro diciendo que es d...  negative   \n",
            "29279  olaznogjunior jessicacediel ivanduque que una ...  negative   \n",
            "28153  cecastaneda petrogustavo a_ordonezm 16oscarsan...  negative   \n",
            "29647  juanescor apoilonia ivanduque yo no soy petris...  negative   \n",
            "\n",
            "              score  \n",
            "16959  1.000000e+00  \n",
            "25674  1.000000e+00  \n",
            "24286  9.999999e-01  \n",
            "28001  9.999998e-01  \n",
            "25497  9.999986e-01  \n",
            "...             ...  \n",
            "8283   1.569570e-20  \n",
            "11424  1.334412e-20  \n",
            "29279  3.530098e-21  \n",
            "28153  1.880022e-21  \n",
            "29647  3.031789e-23  \n",
            "\n",
            "[30000 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spanish.loc[25497,\"tweetText\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHQa09Me3GFr",
        "outputId": "630b29b5-05f5-4ed7-c6d2-eb930e4948e1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en el hotel ghl de la ciudad de barranquilla el ex gobernador del atlantico y ex ministro de minas carlos rodado noriega, en compra de voto por el candidato ivan duque costo de este 70000 mol pesos,  para refrigerios y transporte en taxi o buses.gustavobolivar petrogustavo https://t.co/w4m1fcr6ov\n"
          ]
        }
      ]
    }
  ]
}